{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Discretize the state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LSTM import LSTM\n",
    "from System import Plant\n",
    "from Policy import Estimator\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)\n",
    "\n",
    "resolution = 0.1 #unit: kW \n",
    "control_resolution = 1 # TODO\n",
    "\n",
    "c_dis = np.arange(start=0, stop=7.01, step=resolution) # TODO kW`h should has larger resolution\n",
    "p_dis = np.arange(start=0, stop=15.01, step=resolution) \n",
    "l_dis = np.arange(start=0, stop=10.01, step=resolution)\n",
    "u_dis = np.arange(start=-5, stop=4, step=control_resolution)\n",
    "\n",
    "n = c_dis.shape[0] * p_dis.shape[0] * l_dis.shape[0]\n",
    "print(\"Size of state space: {}\".format(n))\n",
    "print(\"Size of action space: {}\".format(u_dis.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_idx(list, target):\n",
    "    '''\n",
    "    find closest index in list to target\n",
    "    '''\n",
    "    return np.argmin(np.abs(list - target))\n",
    "\n",
    "def get_idx(p_idx, c_idx, l_idx):\n",
    "    '''\n",
    "    encode p_idx, c_idx, l_idx to a single integer\n",
    "    '''\n",
    "    return (p_idx * c_dis.shape[0] * l_dis.shape[0] + \n",
    "            c_idx * l_dis.shape[0]                  +\n",
    "            l_idx)\n",
    "    \n",
    "def get_pcl(idx):\n",
    "    '''\n",
    "    decode p_idx, c_idx, l_idx from a single integer\n",
    "    '''\n",
    "    p_idx = idx // (c_dis.shape[0] * l_dis.shape[0])\n",
    "    c_idx = (idx % (c_dis.shape[0] * l_dis.shape[0])) // l_dis.shape[0]\n",
    "    l_idx = idx % l_dis.shape[0]\n",
    "    return [p_dis[p_idx], c_dis[c_idx], l_dis[l_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1/30 # hour\n",
    "n_sample = 100 #number of monte carlo samples\n",
    "\n",
    "\n",
    "P_trans = {}\n",
    "plant = Plant(dt=dt)\n",
    "estimator = Estimator()\n",
    "std = 0.1 # variation of estimated load\n",
    "\n",
    "for l_idx, l in enumerate(l_dis):\n",
    "    l_hat = estimator.estimate(l)\n",
    "    # l_hat = l\n",
    "    l_hats = np.random.normal(loc=l_hat, scale=std, size=n_sample)\n",
    "    for p_idx, p in enumerate(tqdm(p_dis)):\n",
    "        for c_idx, c in enumerate(c_dis):\n",
    "            for u_idx, u in enumerate(u_dis):\n",
    "                for l_hat in l_hats:\n",
    "                    state_idx = get_idx(p_idx, c_idx, l_idx)\n",
    "                    plant.reset(c, p, l)\n",
    "                    plant.step(u, l_hat)\n",
    "                    hit_state_idx = get_idx(close_idx(p_dis, plant.p),\n",
    "                                            close_idx(c_dis, plant.battery.c),\n",
    "                                            close_idx(l_dis, plant.l))\n",
    "                    if P_trans.__contains__((state_idx, u_idx, hit_state_idx)):\n",
    "                        P_trans[state_idx, u_idx, hit_state_idx] += (1/n_sample)\n",
    "                    else:\n",
    "                        P_trans[state_idx, u_idx, hit_state_idx] = (1/n_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save P_trans dic (super large, takes much time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "P_trans_file = open(\"P_trans.pkl\", \"wb\")\n",
    "pickle.dump(P_trans, P_trans_file)\n",
    "P_trans_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the transition matrix is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_idx = 0\n",
    "u_idx = 0\n",
    "\n",
    "sum = 0\n",
    "for j in range(n):\n",
    "    if P_trans.__contains__((state_idx, u_idx, j)):\n",
    "        sum += P_trans[state_idx, u_idx, j]\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "P_trans_tensor = torch.sparse_coo_tensor(list(zip(*P_trans.keys())), list(P_trans.values()), size=(n, u_dis.shape[0], n), device=device)\n",
    "\n",
    "T  = 360\n",
    "J = torch.tensor([get_pcl(i)[0] for i in range(n)], device=device).float()\n",
    "Actions = torch.zeros(size=(T, n), device=device)\n",
    "\n",
    "for t in range(T-1, 0, -1):\n",
    "    for i in tqdm(range(n)): \n",
    "        J[i], Actions[t][i] = torch.min(P_trans_tensor[i] @ J, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Actions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "Actions = Actions.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')  # read df from csv file\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d-%m-%Y %H;%M:%S')\n",
    "df = df.drop(columns=['Date', 'Time'])\n",
    "df.set_index('Datetime', inplace=True)\n",
    "\n",
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "simu_time = 12 # hour\n",
    "simu_step = int(simu_time / dt)\n",
    "cur_time = df.index[0] #2007-10-01 00:00:00 \n",
    "\n",
    "peaks = []\n",
    "loads = []\n",
    "times = []\n",
    "\n",
    "env = Plant(dt=dt)\n",
    "p, c, l = env.reset(init_battery=0, init_peak=0, init_load=0)\n",
    "for i in range(simu_step):\n",
    "    real_load = df.loc[cur_time, 'Load']\n",
    "    state_idx = get_idx(close_idx(p_dis, p), close_idx(c_dis, c), close_idx(l_dis, real_load))\n",
    "    action_idx = int(Actions[i%T][state_idx].item())\n",
    "    p, c, l = env.step(u_dis[action_idx], real_load)\n",
    "    print(\"action: {}, c: {}, load: {}\".format(u_dis[action_idx], c, l))\n",
    "    cur_time += datetime.timedelta(hours=1/30)\n",
    "    times.append(cur_time)\n",
    "    peaks.append(p)\n",
    "    loads.append(l)\n",
    "\n",
    "fig, axs = plt.subplots(1, figsize=(16, 8))\n",
    "axs.plot(times, peaks, label='Peak')\n",
    "axs.plot(times, loads, label='Real Load')\n",
    "axs.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e0b108776c78b5cda65fd4c3038f220ed3a169480f8d80518a0bf08276259c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('robo_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
